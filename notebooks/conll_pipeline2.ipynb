{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import spacy\n",
    "import numpy as np\n",
    "import json\n",
    "import difflib\n",
    "import math\n",
    "from num2words import num2words\n",
    "#sys.path.insert(0,'/home/vishesh/TUM/Thesis/huggingface/neuralcoref') \n",
    "#from neuralcoref import Coref\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from numpy import array\n",
    "import string \n",
    "import gensim\n",
    "import time\n",
    "import os\n",
    "word2vec = gensim.models.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"/home/vishesh/TUM/Thesis/glove6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(join(GLOVE_DIR, 'glove.6B.50d.w2vformat.txt'), binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_file_to_list(file):\n",
    "    train_list = []\n",
    "    for line in file:\n",
    "        train_list.append(line)\n",
    "    return train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_documents(train_file):\n",
    "    train_list = train_file_to_list(train_file)\n",
    "    document = []\n",
    "    part = []\n",
    "    sentence = ''\n",
    "    for i in range (len(train_list)):\n",
    "        if train_list[i] == '\\n':\n",
    "            part.append(sentence)\n",
    "            sentence = ''\n",
    "            continue\n",
    "        cols = train_list[i].split()\n",
    "        if cols[0] == '#begin' or cols[0] == '#end':\n",
    "            if len(part) > 0:\n",
    "                document.append(part)\n",
    "                part = []\n",
    "            continue\n",
    "        else:\n",
    "            if cols[3] == '\\'s' or cols[3] == '.' or cols[3] == ',' or cols[3] == '?':\n",
    "                sentence = sentence.strip() + cols[3] + ' '\n",
    "            else:\n",
    "                sentence += cols[3] + ' '    \n",
    "    return document             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mention_cluster_list(cluster_start, start_pos, cluster_end, end_pos):\n",
    "    cluster_start_end_list = []\n",
    "    for start, pos in zip(cluster_start, start_pos):\n",
    "        cluster = [start, pos]\n",
    "        for i in range(len(cluster_end)):\n",
    "            if cluster_end[i] == start:\n",
    "                cluster.append(end_pos[i])\n",
    "                break\n",
    "        del cluster_end[i]\n",
    "        del end_pos[i]\n",
    "        cluster_start_end_list.append(cluster)\n",
    "    return cluster_start_end_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention(train_list):\n",
    "    cluster_start = []\n",
    "    start_pos = []\n",
    "    cluster_end = []\n",
    "    end_pos = []\n",
    "    i = 1\n",
    "    for line in train_list:\n",
    "        if line == '\\n' or line == '-':\n",
    "            i += 1\n",
    "            continue\n",
    "        part_number = line.split()[1]\n",
    "        coref_col = line.split()[-1]\n",
    "        for j in range (len(coref_col)):\n",
    "            if coref_col[j] == '(':\n",
    "                cluster_start.append((str(part_number) + '_' + re.findall(r'\\d+', coref_col[j+1:])[0]))\n",
    "                start_pos.append(i)\n",
    "            if coref_col[j] == ')':\n",
    "                cluster_end.append((str(part_number)+ '_' + re.findall(r'\\d+', coref_col[:j])[-1]))\n",
    "                end_pos.append(i)            \n",
    "        i += 1\n",
    "    return cluster_start, start_pos, cluster_end, end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention_words(train_file_as_list, pos1, pos2):\n",
    "    mention = ''\n",
    "    for line_no in range(pos1-1, pos2):\n",
    "        word = train_file_as_list[line_no].split()[3]\n",
    "        #if word == '\\'s' or word == ',' or word == '.':\n",
    "        #    mention = mention.strip() + word + ' '\n",
    "        #else:\n",
    "        mention += word + ' '\n",
    "    return mention.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preceding_words(list, pos):\n",
    "    word_part = list[pos-1].split()[1]\n",
    "    i = 2\n",
    "    num_words = 0\n",
    "    word = []\n",
    "    while(True):\n",
    "        if list[pos-i] != '\\n':\n",
    "            if list[pos-i].split()[0] == '#begin' or list[pos-i].split()[0] == '#end':\n",
    "                break\n",
    "            part_no = list[pos-i].split()[1]\n",
    "            if part_no == word_part:\n",
    "                word.append(list[pos-i].split()[3])\n",
    "                num_words += 1\n",
    "            if num_words == 5:\n",
    "                break\n",
    "        i += 1\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_words(list, pos):\n",
    "    pos = pos-1\n",
    "    word_part = list[pos].split()[1]\n",
    "    i = 1\n",
    "    num_words = 0\n",
    "    word = []\n",
    "    while(True):\n",
    "        if list[pos+i] != '\\n':\n",
    "            if list[pos+i].split()[0] == '#begin' or list[pos+i].split()[0] == '#end':\n",
    "                break\n",
    "            part_no = list[pos+i].split()[1]\n",
    "            if part_no == word_part:\n",
    "                word.append(list[pos+i].split()[3])\n",
    "                num_words += 1\n",
    "            if num_words == 5:\n",
    "                break\n",
    "        i += 1\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mention_sentence(train_list, pos):\n",
    "    pos = pos-1\n",
    "    i = 1\n",
    "    start = 0\n",
    "    end = 0\n",
    "    while(True):\n",
    "        if train_list[pos-i] == '\\n':\n",
    "            start = pos-i\n",
    "            break\n",
    "        if train_list[pos-i].split()[0] == '#begin':\n",
    "            start = pos-i\n",
    "            break\n",
    "        i += 1\n",
    "    start += 2\n",
    "    i = 1\n",
    "    while(True):\n",
    "        if train_list[pos+i] == '\\n':\n",
    "            end = pos+i\n",
    "            break\n",
    "        i += 1\n",
    "    sentence = get_mention_words(train_list, start, end)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_dictionary(train_file):\n",
    "    documents = get_documents(train_file)\n",
    "    doc_sent = ''\n",
    "    doc_no = 0\n",
    "    doc_dict = {}\n",
    "    for document in documents:\n",
    "        for part in document:\n",
    "            doc_sent += part\n",
    "        doc_dict[doc_no] = doc_sent\n",
    "        doc_sent = ''\n",
    "        doc_no += 1\n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention_length(mention):\n",
    "    mention_words = mention.split()\n",
    "    mention_len = len(mention_words)\n",
    "    len_in_words = num2words(mention_len)\n",
    "    return len_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pronoun: [1, 0, 0, 0]\n",
    "# proper:  [0, 1, 0, 0]\n",
    "# nominal(common noun): [0, 0, 1, 0]\n",
    "# list:    [0, 0, 0, 1]\n",
    "def mention_type(doc, mention):\n",
    "    # pos 0: pronoun, pos 1: proper noun, pos 2: common noun\n",
    "    token_type = [0, 0, 0]\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON':\n",
    "            token_type[0] += 1\n",
    "        elif token.pos_ == 'PROPN':\n",
    "            token_type[1] += 1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            token_type[2] += 1   \n",
    "    m = max(token_type)\n",
    "    a = [i for i, j in enumerate(token_type) if j == m]  \n",
    "    is_dominant = m >= len(mention.split())/2 \n",
    "    if is_dominant:\n",
    "        if a[0] == 0:\n",
    "            return np.array([1, 0, 0, 0])\n",
    "        if a[0] == 1:\n",
    "            return np.array([0, 1, 0, 0])\n",
    "        if a[0] == 2:\n",
    "            return np.array([0, 0, 1, 0])\n",
    "    else:\n",
    "        return np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_mention_contain(newlist):\n",
    "    for i in range(0, len(newlist)):\n",
    "        start = newlist[i]['mention_start']\n",
    "        end = newlist[i]['mention_end']\n",
    "        for j in range(0, len(newlist)):\n",
    "            c_start = newlist[j]['mention_start']\n",
    "            c_end = newlist[j]['mention_end']\n",
    "            if c_start == start and c_end == end:\n",
    "                continue\n",
    "            if c_start >= start and c_end <= end:\n",
    "                newlist[j]['contained'] = newlist[i]['id']\n",
    "            if c_start >= start and c_start <= end:\n",
    "                newlist[j]['overlap'] = newlist[i]['id']\n",
    "\n",
    "    for k in range(0, len(newlist)):\n",
    "        if 'contained' in newlist[k]:\n",
    "            continue\n",
    "        else:\n",
    "            newlist[k]['contained'] = False\n",
    "        if 'overlap' in newlist[k]:\n",
    "            continue\n",
    "        else:\n",
    "            newlist[k]['overlap'] = False\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_with_N_digits(n):\n",
    "    range_start = 10**(n-1)\n",
    "    range_end = (10**n)-1\n",
    "    return randint(range_start, range_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not used\n",
    "def get_all_mentions(train_file):\n",
    "    documents = get_documents(train_file)\n",
    "    each_doc = ''\n",
    "    mention_list = []\n",
    "    for docs in documents:\n",
    "        for d in docs:\n",
    "            each_doc += d\n",
    "        print (each_doc)\n",
    "        clusters = coref.one_shot_coref(utterances=each_doc)\n",
    "        mention_list.append(coref.get_mentions())\n",
    "        each_doc = ''\n",
    "    return mention_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not used\n",
    "def get_all_mention_cluster(file_path, train_file):\n",
    "    mention_list = get_all_mentions(file_path)\n",
    "    train_list = train_file_to_list(train_file)\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    mention_cluster = []\n",
    "    for doc_num in range(0, len(mention_list)):\n",
    "        for men in mention_list[doc_num]:\n",
    "            for i in range(0, len(train_list)):\n",
    "                if train_list[i] != '\\n' and train_list[i].split()[0] != '#begin' and train_list[i].split()[0] != '#end':\n",
    "                    if train_list[i].split()[3] == str(men[0]) and train_list[i].split()[1] == str(doc_num):\n",
    "                        len_mention = len(men)\n",
    "                        flag = True\n",
    "                        for j, k in zip(men, train_list[i:i+len_mention]):\n",
    "                            if k != '\\n' and k.split()[0] != '#begin' and k.split()[0] != '#end':\n",
    "                                if str(j) != k.split()[3]:\n",
    "                                    flag = False\n",
    "                        start = i+1\n",
    "                        end = i+len_mention\n",
    "                        for s, e in zip(start_index, end_index):\n",
    "                            if s == start and e == end:\n",
    "                                flag = False\n",
    "\n",
    "                        if flag == True:\n",
    "                            start_index.append(start)\n",
    "                            end_index.append(end)\n",
    "                            dummy_list = []\n",
    "                            dummy_list.append(str(doc_num)+'_' + str(random_with_N_digits(10)))\n",
    "                            dummy_list.append(start)\n",
    "                            dummy_list.append(end)\n",
    "                            mention_cluster.append(dummy_list)\n",
    "                            break\n",
    "    return mention_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(mention_info):\n",
    "    doc_count = '0'\n",
    "    count = 0\n",
    "    i = 0\n",
    "    mentions_in_each_doc = []\n",
    "    for m in mention_info:\n",
    "        if m['id'].split('_')[0] == doc_count:\n",
    "            count += 1\n",
    "        else:\n",
    "            mentions_in_each_doc.append(count)\n",
    "            doc_count = m['id'].split('_')[0]\n",
    "            count = 1\n",
    "        m['index'] = count\n",
    "    mentions_in_each_doc.append(count)\n",
    "    doc_count = '0'\n",
    "    for m in mention_info:\n",
    "        if m['id'].split('_')[0] == doc_count:\n",
    "            m['mention_position'] = m['index']/mentions_in_each_doc[i]\n",
    "        else:\n",
    "            doc_count = m['id'].split('_')[0]\n",
    "            i += 1\n",
    "            m['mention_position'] = m['index']/mentions_in_each_doc[i]\n",
    "            \n",
    "    return mention_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_dictionary(train_file):\n",
    "    mention_info = []\n",
    "    train_list = train_file_to_list(train_file)\n",
    "    cluster_start, start_pos, cluster_end, end_pos = get_mention(train_list)\n",
    "    mention_cluster = create_mention_cluster_list(cluster_start, start_pos, cluster_end, end_pos)\n",
    "    for m in mention_cluster:\n",
    "        mention_dict = {}\n",
    "        mention_words = get_mention_words(train_list, m[1], m[2])\n",
    "        doc = nlp(mention_words)\n",
    "        mention_dict['id'] = m[0]\n",
    "        mention_dict['mention_start'] = m[1]\n",
    "        mention_dict['mention_end'] = m[2]\n",
    "        mention_dict['mention'] = mention_words\n",
    "        mention_dict['first_word'] = mention_words.split()[0]\n",
    "        mention_dict['last_word'] = mention_words.split()[-1]\n",
    "        if mention_words.isdigit() or mention_words == 'its' or mention_words.lower() == 'that' or mention_words.lower() == 'this':\n",
    "            mention_dict['head_word'] = ''\n",
    "        else:\n",
    "            if len(list(doc.noun_chunks)) > 0:\n",
    "                mention_dict['head_word'] = list(doc.noun_chunks)[0].root.head.text\n",
    "            else:\n",
    "                mention_dict['head_word'] = ''                        \n",
    "        mention_dict['pre_words'] = get_preceding_words(train_list, m[1])\n",
    "        mention_dict['next_words'] = get_next_words(train_list, m[2])\n",
    "        mention_dict['mention_sentence'] = mention_sentence(train_list, m[1])\n",
    "        mention_dict['mention_type'] = mention_type(doc, mention_words).tolist()\n",
    "        mention_dict['mention_length'] = get_mention_length(mention_words)\n",
    "        mention_dict['speaker'] = train_list[m[1] - 1].split()[9]\n",
    "        mention_info.append(mention_dict)\n",
    "    \n",
    "    mention_info = sorted(mention_info, key=lambda k: k['mention_start'])\n",
    "    mention_info = check_mention_contain(mention_info)\n",
    "    mention_info = get_index(mention_info)\n",
    "    return mention_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(a):\n",
    "    d = np.zeros((10))\n",
    "    d[a == 0, 0] = 1\n",
    "    d[a == 1, 1] = 1\n",
    "    d[a == 2, 2] = 1\n",
    "    d[a == 3, 3] = 1\n",
    "    d[a == 4, 4] = 1\n",
    "    d[(5 <= a) & (a < 8), 5] = 1\n",
    "    d[(8 <= a) & (a < 16), 6] = 1\n",
    "    d[(16 <= a) & (a < 32), 7] = 1\n",
    "    d[(a >= 32) & (a < 64), 8] = 1\n",
    "    d[a >= 64, 9] = 1\n",
    "    return d.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention_pairs(train_file):\n",
    "    mention_info = train_dictionary(train_file)\n",
    "    mention_pair_list = []\n",
    "    for i in range(1, len(mention_info)):\n",
    "        for j in range(0, i):\n",
    "            pair = []\n",
    "            if mention_info[i]['id'].split('_')[0] == mention_info[j]['id'].split('_')[0]:\n",
    "                pair.append(mention_info[i])\n",
    "                pair.append(mention_info[j])\n",
    "                if mention_info[i]['id'] == mention_info[j]['id']:\n",
    "                    pair.append({'coref': 1})\n",
    "                else:\n",
    "                    if j % 2 == 0 or j % 3 == 0 or j % 5 == 0 or j % 7 == 0 or j % 11 == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        pair.append({'coref': 0})\n",
    "                mention_pair_list.append(pair)\n",
    "                \n",
    "    mention_pair_list = get_sentence_dist(mention_pair_list, train_file)\n",
    "    \n",
    "    return mention_pair_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_dist(mention_pair_list, train_file):\n",
    "    train_list = train_file_to_list(train_file)\n",
    "    for m in mention_pair_list:\n",
    "        count = 0\n",
    "        m1 = m[0]['mention_start']\n",
    "        m2 = m[1]['mention_start']\n",
    "        if m1 < m2:\n",
    "            for t in range(m1, m2+1):\n",
    "                if train_list[t] == '\\n':\n",
    "                    count += 1\n",
    "        seq=difflib.SequenceMatcher(None, m[0]['mention'],m[1]['mention'])\n",
    "        score = seq.ratio()\n",
    "        m.append({'sentence_dist_count': distance(count)})\n",
    "        m.append({'mention_dist_count': distance(m[0]['index'] - m[1]['index'])})\n",
    "        if m[1]['overlap'] == m[0]['id']:\n",
    "            m.append({'overlap': 1})\n",
    "        else:\n",
    "            m.append({'overlap': 0})\n",
    "        if m[1]['speaker'] == m[0]['speaker']:\n",
    "            m.append({'speaker': 1})\n",
    "        else:\n",
    "            m.append({'speaker': 0})\n",
    "        if m[1]['head_word'] == m[0]['head_word']:\n",
    "            m.append({'head_match': 1})\n",
    "        else:\n",
    "            m.append({'head_match': 0})\n",
    "        if m[1]['mention'] == m[0]['mention']:\n",
    "            m.append({'mention_exact_match': 1})\n",
    "        else:\n",
    "            m.append({'mention_exact_match': 0})\n",
    "        if score > 0.6:\n",
    "            m.append({'mention_partial_match': 1})\n",
    "        else:\n",
    "            m.append({'mention_partial_match': 0})\n",
    "    return mention_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('/home/vishesh/TUM/Thesis/coref-json/trainfile1.json', 'w') as outfile:\n",
    "#    json.dump(pairs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('/home/vishesh/TUM/Thesis/coref-json/documents.json', 'w') as outfile:\n",
    "#    json.dump(doc_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    word = word.lower()\n",
    "    if len(word) > 1:\n",
    "        word = word.translate(table)\n",
    "    try:\n",
    "        vec = model[word]\n",
    "    except:\n",
    "        vec = np.zeros((50, 1))\n",
    "    return vec.reshape((50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_vector(word_list):\n",
    "    sum = np.zeros((50, 1))\n",
    "    for i in range(0, len(word_list)):\n",
    "        sum += get_vector(word_list[i])\n",
    "    average_vector = sum/(i+1)\n",
    "    return average_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_docs_average(doc_dict):\n",
    "    doc_avg = []\n",
    "    for d in doc_dict:\n",
    "        doc_avg.append(get_average_vector(doc_dict[d].split()))\n",
    "    return doc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pair_features(feature_list):\n",
    "    \n",
    "    # distance features\n",
    "    mention_dist = np.array(feature_list[4]['mention_dist_count']).reshape((10, 1))\n",
    "    s_dist = np.array(feature_list[3]['sentence_dist_count']).reshape((10, 1))\n",
    "    overlap = np.array(feature_list[5]['overlap']).reshape((1, 1))\n",
    "    \n",
    "    # speaker feature\n",
    "    speaker = np.array(feature_list[6]['speaker']).reshape((1, 1))\n",
    "    \n",
    "    # string matching features\n",
    "    head_match = np.array(feature_list[7]['head_match']).reshape((1, 1))\n",
    "    mention_exact_match = np.array(feature_list[8]['mention_exact_match']).reshape((1, 1))\n",
    "    mention_partial_match = np.array(feature_list[9]['mention_partial_match']).reshape((1, 1))\n",
    "    \n",
    "    pair_features = np.concatenate((mention_dist, s_dist, overlap, speaker, head_match, \\\n",
    "                                   mention_exact_match, mention_partial_match))\n",
    "    \n",
    "    return pair_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p: previous, n: next, w: words, a: average, s: sentence\n",
    "def get_mention_features(mention, doc_average):\n",
    "    features = []\n",
    "    #head_w = get_vector(mention['head_word'])\n",
    "    first_w = get_vector(mention['first_word'])\n",
    "    last_w = get_vector(mention['last_word'])\n",
    "    mention_length = get_vector(mention['mention_length'])\n",
    "    mention_type = np.array(mention['mention_type']).reshape((4, 1))\n",
    "    mention_position = np.array(mention['mention_position']).reshape((1, 1))\n",
    "    if mention['contained'] == False:\n",
    "        mention_contain = np.zeros((1, 1))\n",
    "    else:\n",
    "        mention_contain = np.ones((1, 1))\n",
    "    if len(mention['pre_words']) > 0:\n",
    "        mention_p_w1 = get_vector(mention['pre_words'][0])\n",
    "    else:\n",
    "        mention_p_w1 = np.zeros((50, 1))\n",
    "    if len(mention['pre_words']) > 1:\n",
    "        mention_p_w2 = get_vector(mention['pre_words'][1])\n",
    "    else:\n",
    "        mention_p_w2 = np.zeros((50, 1))\n",
    "    if len(mention['next_words']) > 0:\n",
    "        mention_n_w1 = get_vector(mention['next_words'][0])\n",
    "    else:\n",
    "        mention_n_w1 = np.zeros((50, 1))\n",
    "    if len(mention['next_words']) > 1:\n",
    "        mention_n_w2 = get_vector(mention['next_words'][1])\n",
    "    else:\n",
    "        mention_n_w2 = np.zeros((50, 1))\n",
    "    if len(mention['pre_words']) > 0:\n",
    "        mention_p_w_a = get_average_vector(mention['pre_words'])\n",
    "    else:\n",
    "        mention_p_w_a = np.zeros((50, 1))\n",
    "    if len(mention['next_words']) > 0:\n",
    "        mention_n_w_a = get_average_vector(mention['next_words'])\n",
    "    else:\n",
    "        mention_n_w_a = np.zeros((50, 1))\n",
    "    mention_s_a = get_average_vector(mention['mention_sentence'].split())\n",
    "    doc_id = mention['id'].split('_')[0]\n",
    "    doc_avg = doc_average[int(doc_id)]\n",
    "    \n",
    "    \n",
    "    features = np.concatenate((first_w, last_w, mention_p_w1, mention_p_w2, mention_p_w_a, \\\n",
    "                               mention_n_w1, mention_n_w2, mention_n_w_a, mention_s_a, mention_length, \\\n",
    "                               mention_type, mention_position, mention_contain, doc_avg))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_input(pairs, doc_dict):\n",
    "    docs_avg = calculate_docs_average(doc_dict)\n",
    "    input_feature_list = []\n",
    "    i = 0\n",
    "    for m in pairs:\n",
    "        i += 1\n",
    "        input_feature_vector = []\n",
    "        mention_avg = get_average_vector(m[0]['mention'].split())\n",
    "        antecedent_avg = get_average_vector(m[1]['mention'].split())\n",
    "        mention_features = get_mention_features(m[0], docs_avg)\n",
    "        antecedent_features = get_mention_features(m[1], docs_avg)\n",
    "        pair_features = get_pair_features(m)\n",
    "        \n",
    "        input_feature_vector.append(antecedent_avg)\n",
    "        input_feature_vector.append(antecedent_features)\n",
    "        input_feature_vector.append(mention_avg)\n",
    "        input_feature_vector.append(mention_features)\n",
    "        input_feature_vector.append(pair_features)\n",
    "        input_feature_list.append(input_feature_vector)\n",
    "        \n",
    "    return input_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_input_vector(pairs, doc_dict):\n",
    "    feature_input = make_feature_input(pairs, doc_dict)\n",
    "    len_f_input = len(feature_input)\n",
    "    input_ = []\n",
    "    for f_input in feature_input:\n",
    "        con = np.concatenate((f_input[0], f_input[1], f_input[2], f_input[3], f_input[4]))\n",
    "        input_.append(con)\n",
    "        del con\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_output_vector(pairs):\n",
    "    output = []\n",
    "    len_mentions = len(pairs)\n",
    "    for m in pairs:\n",
    "        output.append(m[2]['coref'])\n",
    "    output = np.array(output).reshape((len_mentions, 1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_train_files = '/home/vishesh/TUM/Thesis/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/train/data/english/annotations/'\n",
    "path_to_dev_files = '/home/vishesh/TUM/Thesis/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/development/data/english/annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_file = open(path_to_train_file, 'r')\n",
    "#doc_dict = document_dictionary(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_conll_files = []\n",
    "for path, subdirs, files in os.walk(path_to_dev_files):\n",
    "    for name in files:\n",
    "        if name.endswith(\".gold_conll\"):\n",
    "            list_of_conll_files.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_conll_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network_data(path):\n",
    "    train_file = open(path, 'r')\n",
    "    doc_dict = document_dictionary(train_file)\n",
    "    train_file = open(path, 'r')\n",
    "    pairs = get_mention_pairs(train_file)\n",
    "    input_vector = make_input_vector(pairs, doc_dict)\n",
    "    output_vector = make_output_vector(pairs)\n",
    "    return input_vector, output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_network_data(list_of_conll_files[432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file num: 1\n",
      "file num: 2\n",
      "file num: 3\n",
      "file num: 4\n",
      "file num: 5\n",
      "file num: 6\n",
      "file num: 7\n",
      "file num: 8\n",
      "file num: 9\n",
      "file num: 10\n",
      "file num: 11\n",
      "file num: 12\n",
      "file num: 13\n",
      "file num: 14\n",
      "file num: 15\n",
      "file num: 16\n",
      "file num: 17\n",
      "file num: 18\n",
      "coref: 1\n",
      "file num: 19\n",
      "file num: 20\n",
      "file num: 21\n",
      "coref: 2\n",
      "file num: 22\n",
      "file num: 23\n",
      "file num: 24\n",
      "file num: 25\n",
      "file num: 26\n",
      "file num: 27\n",
      "file num: 28\n",
      "file num: 29\n",
      "file num: 30\n",
      "file num: 31\n",
      "file num: 32\n",
      "file num: 33\n",
      "file num: 34\n",
      "coref: 3\n",
      "file num: 35\n",
      "file num: 36\n",
      "file num: 37\n",
      "file num: 38\n",
      "file num: 39\n",
      "coref: 4\n",
      "file num: 40\n",
      "file num: 41\n",
      "file num: 42\n",
      "file num: 43\n",
      "file num: 44\n",
      "file num: 45\n",
      "file num: 46\n",
      "file num: 47\n",
      "coref: 5\n",
      "File  created.\n",
      "file num: 48\n",
      "file num: 49\n",
      "file num: 50\n",
      "file num: 51\n",
      "file num: 52\n",
      "file num: 53\n",
      "file num: 54\n",
      "file num: 55\n",
      "file num: 56\n",
      "coref: 6\n",
      "file num: 57\n",
      "coref: 7\n",
      "file num: 58\n",
      "file num: 59\n",
      "file num: 60\n",
      "file num: 61\n",
      "file num: 62\n",
      "file num: 63\n",
      "file num: 64\n",
      "file num: 65\n",
      "file num: 66\n",
      "file num: 67\n",
      "file num: 68\n",
      "file num: 69\n",
      "file num: 70\n",
      "file num: 71\n",
      "file num: 72\n",
      "file num: 73\n",
      "coref: 8\n",
      "file num: 74\n",
      "file num: 75\n",
      "file num: 76\n",
      "file num: 77\n",
      "file num: 78\n",
      "file num: 79\n",
      "file num: 80\n",
      "file num: 81\n",
      "file num: 82\n",
      "file num: 83\n",
      "file num: 84\n",
      "file num: 85\n",
      "file num: 86\n",
      "file num: 87\n",
      "file num: 88\n",
      "file num: 89\n",
      "file num: 90\n",
      "file num: 91\n",
      "file num: 92\n",
      "file num: 93\n",
      "file num: 94\n",
      "file num: 95\n",
      "file num: 96\n",
      "file num: 97\n",
      "file num: 98\n",
      "file num: 99\n",
      "file num: 100\n",
      "file num: 101\n",
      "file num: 102\n",
      "coref: 9\n",
      "file num: 103\n",
      "file num: 104\n",
      "file num: 105\n",
      "file num: 106\n",
      "file num: 107\n",
      "file num: 108\n",
      "file num: 109\n",
      "file num: 110\n",
      "file num: 111\n",
      "file num: 112\n",
      "file num: 113\n",
      "coref: 10\n",
      "File  created.\n",
      "file num: 114\n",
      "file num: 115\n",
      "file num: 116\n",
      "file num: 117\n",
      "file num: 118\n",
      "file num: 119\n",
      "file num: 120\n",
      "file num: 121\n",
      "file num: 122\n",
      "file num: 123\n",
      "file num: 124\n",
      "file num: 125\n",
      "file num: 126\n",
      "file num: 127\n",
      "file num: 128\n",
      "file num: 129\n",
      "file num: 130\n",
      "file num: 131\n",
      "coref: 11\n",
      "file num: 132\n",
      "file num: 133\n",
      "file num: 134\n",
      "file num: 135\n",
      "file num: 136\n",
      "file num: 137\n",
      "file num: 138\n",
      "file num: 139\n",
      "file num: 140\n",
      "file num: 141\n",
      "file num: 142\n",
      "file num: 143\n",
      "file num: 144\n",
      "file num: 145\n",
      "file num: 146\n",
      "file num: 147\n",
      "file num: 148\n",
      "file num: 149\n",
      "file num: 150\n",
      "file num: 151\n",
      "file num: 152\n",
      "file num: 153\n",
      "file num: 154\n",
      "file num: 155\n",
      "file num: 156\n",
      "file num: 157\n",
      "file num: 158\n",
      "coref: 12\n",
      "file num: 159\n",
      "file num: 160\n",
      "file num: 161\n",
      "file num: 162\n",
      "file num: 163\n",
      "file num: 164\n",
      "file num: 165\n",
      "file num: 166\n",
      "file num: 167\n",
      "file num: 168\n",
      "file num: 169\n",
      "file num: 170\n",
      "file num: 171\n",
      "file num: 172\n",
      "file num: 173\n",
      "file num: 174\n",
      "file num: 175\n",
      "file num: 176\n",
      "file num: 177\n",
      "file num: 178\n",
      "file num: 179\n",
      "file num: 180\n",
      "file num: 181\n",
      "file num: 182\n",
      "file num: 183\n",
      "file num: 184\n",
      "file num: 185\n",
      "file num: 186\n",
      "file num: 187\n",
      "file num: 188\n",
      "file num: 189\n",
      "file num: 190\n",
      "file num: 191\n",
      "file num: 192\n",
      "file num: 193\n",
      "file num: 194\n",
      "file num: 195\n",
      "file num: 196\n",
      "file num: 197\n",
      "file num: 198\n",
      "file num: 199\n",
      "file num: 200\n",
      "coref: 13\n",
      "file num: 201\n",
      "coref: 14\n",
      "file num: 202\n",
      "coref: 15\n",
      "File  created.\n",
      "file num: 203\n",
      "coref: 16\n",
      "file num: 204\n",
      "coref: 17\n",
      "file num: 205\n",
      "coref: 18\n",
      "file num: 206\n",
      "coref: 19\n",
      "file num: 207\n",
      "coref: 20\n",
      "File  created.\n",
      "file num: 208\n",
      "coref: 21\n",
      "file num: 209\n",
      "coref: 22\n",
      "file num: 210\n",
      "coref: 23\n",
      "file num: 211\n",
      "coref: 24\n",
      "file num: 212\n",
      "coref: 25\n",
      "File  created.\n",
      "file num: 213\n",
      "coref: 26\n",
      "file num: 214\n",
      "coref: 27\n",
      "file num: 215\n",
      "coref: 28\n",
      "file num: 216\n",
      "coref: 29\n",
      "file num: 217\n",
      "coref: 30\n",
      "File  created.\n",
      "file num: 218\n",
      "coref: 31\n",
      "file num: 219\n",
      "coref: 32\n",
      "file num: 220\n",
      "coref: 33\n",
      "file num: 221\n",
      "coref: 34\n",
      "file num: 222\n",
      "coref: 35\n",
      "File  created.\n",
      "file num: 223\n",
      "coref: 36\n",
      "file num: 224\n",
      "coref: 37\n",
      "file num: 225\n",
      "coref: 38\n",
      "file num: 226\n",
      "coref: 39\n",
      "file num: 227\n",
      "coref: 40\n",
      "File  created.\n",
      "file num: 228\n",
      "coref: 41\n",
      "file num: 229\n",
      "coref: 42\n",
      "file num: 230\n",
      "coref: 43\n",
      "file num: 231\n",
      "coref: 44\n",
      "file num: 232\n",
      "coref: 45\n",
      "File  created.\n",
      "file num: 233\n",
      "coref: 46\n",
      "file num: 234\n",
      "coref: 47\n",
      "file num: 235\n",
      "coref: 48\n",
      "file num: 236\n",
      "coref: 49\n",
      "file num: 237\n",
      "coref: 50\n",
      "File  created.\n",
      "file num: 238\n",
      "coref: 51\n",
      "file num: 239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8f55789f12eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FILES = 100\\nnum_train_files = len(list_of_conll_files)\\ncount = 0\\nnum = 0\\nfile_num = 1\\nfor i in range (0, FILES):\\n    input_files_vector = []\\n    output_files_vector = []\\n    for j in range(math.ceil((i/FILES) * num_train_files), math.ceil(((i+1)/FILES) * num_train_files)):\\n        num += 1\\n        print ('file num: ' + str(num))\\n        i_vector, o_vector = train_network_data(list_of_conll_files[j])\\n        if len(i_vector) > 0:\\n            input_files_vector.append(i_vector)\\n            output_files_vector.append(o_vector)\\n            count += 1\\n            print ('coref: ' + str(count))\\n            if count % 5 == 0:\\n                ffnn_input = []\\n                ffnn_output = []\\n                for inp_vector, out_vector in zip(input_files_vector, output_files_vector):\\n                    for inp, out in zip(inp_vector, out_vector):\\n                        ffnn_input.append(inp)\\n                        ffnn_output.append(out)\\n                np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/dev/ffnn_dev_' + str(file_num), ffnn_input, allow_pickle=True, fix_imports=True)    \\n                np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/dev/ffnn_labels_' + str(file_num), ffnn_output, allow_pickle=True, fix_imports=True)\\n                print ('File  created.')\\n                file_num += 1\\nnp.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/dev/ffnn_dev_' + str(i), ffnn_input, allow_pickle=True, fix_imports=True)    \\nnp.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/dev/ffnn_labels_' + str(i), ffnn_output, allow_pickle=True, fix_imports=True)\\nprint ('File  created.')                \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vishesh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/vishesh/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishesh/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-4fcca81e4146>\u001b[0m in \u001b[0;36mtrain_network_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mention_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minput_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_input_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moutput_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_output_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-4b3c908dcf72>\u001b[0m in \u001b[0;36mmake_input_vector\u001b[0;34m(pairs, doc_dict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_input_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeature_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_feature_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlen_f_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-da1b82e05ebc>\u001b[0m in \u001b[0;36mmake_feature_input\u001b[0;34m(pairs, doc_dict)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mantecedent_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mention'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmention_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mention_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mantecedent_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mention_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpair_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pair_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-18c3e188581b>\u001b[0m in \u001b[0;36mget_mention_features\u001b[0;34m(mention, doc_average)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmention_n_w_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmention_s_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mention_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdoc_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdoc_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_average\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-eeeee5e164e1>\u001b[0m in \u001b[0;36mget_average_vector\u001b[0;34m(word_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maverage_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maverage_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c6b50cf1648b>\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c6b50cf1648b>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FILES = 100\n",
    "num_train_files = len(list_of_conll_files)\n",
    "count = 0\n",
    "num = 0\n",
    "file_num = 1\n",
    "for i in range (0, FILES):\n",
    "    input_files_vector = []\n",
    "    output_files_vector = []\n",
    "    for j in range(math.ceil((i/FILES) * num_train_files), math.ceil(((i+1)/FILES) * num_train_files)):\n",
    "        num += 1\n",
    "        print ('file num: ' + str(num))\n",
    "        i_vector, o_vector = train_network_data(list_of_conll_files[j])\n",
    "        if len(i_vector) > 0:\n",
    "            input_files_vector.append(i_vector)\n",
    "            output_files_vector.append(o_vector)\n",
    "            count += 1\n",
    "            print ('coref: ' + str(count))\n",
    "            if count % 5 == 0:\n",
    "                ffnn_input = []\n",
    "                ffnn_output = []\n",
    "                for inp_vector, out_vector in zip(input_files_vector, output_files_vector):\n",
    "                    for inp, out in zip(inp_vector, out_vector):\n",
    "                        ffnn_input.append(inp)\n",
    "                        ffnn_output.append(out)\n",
    "                np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/new/ffnn_train_' + str(file_num), ffnn_input, allow_pickle=True, fix_imports=True)    \n",
    "                np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/new/ffnn_labels_' + str(file_num), ffnn_output, allow_pickle=True, fix_imports=True)\n",
    "                print ('File  created.')\n",
    "                file_num += 1\n",
    "np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/new/ffnn_train_' + str(i), ffnn_input, allow_pickle=True, fix_imports=True)    \n",
    "np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/new/ffnn_labels_' + str(i), ffnn_output, allow_pickle=True, fix_imports=True)\n",
    "print ('File  created.')                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file num: 1\n",
      "file num: 2\n",
      "file num: 3\n",
      "file num: 4\n",
      "file num: 5\n",
      "file num: 6\n",
      "file num: 7\n",
      "file num: 8\n",
      "file num: 9\n",
      "file num: 10\n",
      "file num: 11\n",
      "file num: 12\n",
      "file num: 13\n",
      "file num: 14\n",
      "file num: 15\n",
      "file num: 16\n",
      "file num: 17\n",
      "file num: 18\n",
      "coref: 1\n",
      "file num: 19\n",
      "file num: 20\n",
      "file num: 21\n",
      "coref: 2\n",
      "file num: 22\n",
      "file num: 23\n",
      "file num: 24\n",
      "file num: 25\n",
      "file num: 26\n",
      "file num: 27\n",
      "file num: 28\n",
      "file num: 29\n",
      "file num: 30\n",
      "file num: 31\n",
      "file num: 32\n",
      "file num: 33\n",
      "file num: 34\n",
      "coref: 3\n",
      "file num: 35\n",
      "file num: 36\n",
      "file num: 37\n",
      "file num: 38\n",
      "file num: 39\n",
      "coref: 4\n",
      "file num: 40\n",
      "file num: 41\n",
      "file num: 42\n",
      "file num: 43\n",
      "file num: 44\n",
      "file num: 45\n",
      "file num: 46\n",
      "file num: 47\n",
      "coref: 5\n",
      "file num: 48\n",
      "file num: 49\n",
      "file num: 50\n",
      "file num: 51\n",
      "file num: 52\n",
      "file num: 53\n",
      "file num: 54\n",
      "file num: 55\n",
      "file num: 56\n",
      "coref: 6\n",
      "file num: 57\n",
      "coref: 7\n",
      "file num: 58\n",
      "file num: 59\n",
      "file num: 60\n",
      "file num: 61\n",
      "file num: 62\n",
      "file num: 63\n",
      "file num: 64\n",
      "file num: 65\n",
      "file num: 66\n",
      "file num: 67\n",
      "file num: 68\n",
      "file num: 69\n",
      "file num: 70\n",
      "file num: 71\n",
      "file num: 72\n",
      "file num: 73\n",
      "coref: 8\n",
      "file num: 74\n",
      "file num: 75\n",
      "file num: 76\n",
      "file num: 77\n",
      "file num: 78\n",
      "file num: 79\n",
      "file num: 80\n",
      "file num: 81\n",
      "file num: 82\n",
      "file num: 83\n",
      "file num: 84\n",
      "file num: 85\n",
      "file num: 86\n",
      "file num: 87\n",
      "file num: 88\n",
      "file num: 89\n",
      "file num: 90\n",
      "file num: 91\n",
      "file num: 92\n",
      "file num: 93\n",
      "file num: 94\n",
      "file num: 95\n",
      "file num: 96\n",
      "file num: 97\n",
      "file num: 98\n",
      "file num: 99\n",
      "file num: 100\n",
      "file num: 101\n",
      "file num: 102\n",
      "coref: 9\n",
      "file num: 103\n",
      "file num: 104\n",
      "file num: 105\n",
      "file num: 106\n",
      "file num: 107\n",
      "file num: 108\n",
      "file num: 109\n",
      "file num: 110\n",
      "file num: 111\n",
      "file num: 112\n",
      "file num: 113\n",
      "coref: 10\n",
      "file num: 114\n",
      "file num: 115\n",
      "file num: 116\n",
      "file num: 117\n",
      "file num: 118\n",
      "file num: 119\n",
      "file num: 120\n",
      "file num: 121\n",
      "file num: 122\n",
      "file num: 123\n",
      "file num: 124\n",
      "file num: 125\n",
      "file num: 126\n",
      "file num: 127\n",
      "file num: 128\n",
      "file num: 129\n",
      "file num: 130\n",
      "file num: 131\n",
      "coref: 11\n",
      "file num: 132\n",
      "file num: 133\n",
      "file num: 134\n",
      "file num: 135\n",
      "file num: 136\n",
      "file num: 137\n",
      "file num: 138\n",
      "file num: 139\n",
      "file num: 140\n",
      "file num: 141\n",
      "file num: 142\n",
      "file num: 143\n",
      "file num: 144\n",
      "file num: 145\n",
      "file num: 146\n",
      "file num: 147\n",
      "file num: 148\n",
      "file num: 149\n",
      "file num: 150\n",
      "file num: 151\n",
      "file num: 152\n",
      "file num: 153\n",
      "file num: 154\n",
      "file num: 155\n",
      "file num: 156\n",
      "file num: 157\n",
      "file num: 158\n",
      "coref: 12\n",
      "file num: 159\n",
      "file num: 160\n",
      "file num: 161\n",
      "file num: 162\n",
      "file num: 163\n",
      "file num: 164\n",
      "file num: 165\n",
      "file num: 166\n",
      "file num: 167\n",
      "file num: 168\n",
      "file num: 169\n",
      "file num: 170\n",
      "file num: 171\n",
      "file num: 172\n",
      "file num: 173\n",
      "file num: 174\n",
      "file num: 175\n",
      "file num: 176\n",
      "file num: 177\n",
      "file num: 178\n",
      "file num: 179\n",
      "file num: 180\n",
      "file num: 181\n",
      "file num: 182\n",
      "file num: 183\n",
      "file num: 184\n",
      "file num: 185\n",
      "file num: 186\n",
      "file num: 187\n",
      "file num: 188\n",
      "file num: 189\n",
      "file num: 190\n",
      "file num: 191\n",
      "file num: 192\n",
      "file num: 193\n",
      "file num: 194\n",
      "file num: 195\n",
      "file num: 196\n",
      "file num: 197\n",
      "file num: 198\n",
      "file num: 199\n",
      "file num: 200\n",
      "coref: 13\n",
      "file num: 201\n",
      "coref: 14\n",
      "file num: 202\n",
      "coref: 15\n",
      "file num: 203\n",
      "coref: 16\n",
      "file num: 204\n",
      "coref: 17\n",
      "file num: 205\n",
      "coref: 18\n",
      "file num: 206\n",
      "coref: 19\n",
      "file num: 207\n",
      "coref: 20\n",
      "file num: 208\n",
      "coref: 21\n",
      "file num: 209\n",
      "coref: 22\n",
      "file num: 210\n",
      "coref: 23\n",
      "file num: 211\n",
      "coref: 24\n",
      "file num: 212\n",
      "coref: 25\n",
      "file num: 213\n",
      "coref: 26\n",
      "file num: 214\n",
      "coref: 27\n",
      "file num: 215\n",
      "coref: 28\n",
      "file num: 216\n",
      "coref: 29\n",
      "file num: 217\n",
      "coref: 30\n",
      "file num: 218\n",
      "coref: 31\n",
      "file num: 219\n",
      "coref: 32\n",
      "file num: 220\n",
      "coref: 33\n",
      "file num: 221\n",
      "coref: 34\n",
      "file num: 222\n",
      "coref: 35\n",
      "file num: 223\n",
      "coref: 36\n",
      "file num: 224\n",
      "coref: 37\n",
      "file num: 225\n",
      "coref: 38\n",
      "file num: 226\n",
      "coref: 39\n",
      "file num: 227\n",
      "coref: 40\n",
      "file num: 228\n",
      "coref: 41\n",
      "file num: 229\n",
      "coref: 42\n",
      "file num: 230\n",
      "coref: 43\n",
      "file num: 231\n",
      "coref: 44\n",
      "file num: 232\n",
      "coref: 45\n",
      "file num: 233\n",
      "coref: 46\n",
      "file num: 234\n",
      "coref: 47\n",
      "file num: 235\n",
      "coref: 48\n",
      "file num: 236\n",
      "coref: 49\n",
      "file num: 237\n",
      "coref: 50\n",
      "file num: 238\n",
      "coref: 51\n",
      "file num: 239\n",
      "coref: 52\n",
      "file num: 240\n",
      "coref: 53\n",
      "file num: 241\n",
      "coref: 54\n",
      "file num: 242\n",
      "coref: 55\n",
      "file num: 243\n",
      "coref: 56\n",
      "file num: 244\n",
      "coref: 57\n",
      "file num: 245\n",
      "coref: 58\n",
      "file num: 246\n",
      "coref: 59\n",
      "file num: 247\n",
      "coref: 60\n",
      "file num: 248\n",
      "coref: 61\n",
      "file num: 249\n",
      "coref: 62\n",
      "file num: 250\n",
      "coref: 63\n",
      "file num: 251\n",
      "coref: 64\n",
      "file num: 252\n",
      "coref: 65\n",
      "file num: 253\n",
      "coref: 66\n",
      "file num: 254\n",
      "coref: 67\n",
      "file num: 255\n",
      "coref: 68\n",
      "file num: 256\n",
      "coref: 69\n",
      "file num: 257\n",
      "coref: 70\n",
      "file num: 258\n",
      "coref: 71\n",
      "file num: 259\n",
      "coref: 72\n",
      "file num: 260\n",
      "coref: 73\n",
      "file num: 261\n",
      "coref: 74\n",
      "file num: 262\n",
      "coref: 75\n",
      "file num: 263\n",
      "coref: 76\n",
      "file num: 264\n",
      "coref: 77\n",
      "file num: 265\n",
      "coref: 78\n",
      "file num: 266\n",
      "coref: 79\n",
      "file num: 267\n",
      "coref: 80\n",
      "file num: 268\n",
      "coref: 81\n",
      "file num: 269\n",
      "coref: 82\n",
      "file num: 270\n",
      "coref: 83\n",
      "file num: 271\n",
      "coref: 84\n",
      "file num: 272\n",
      "coref: 85\n",
      "file num: 273\n",
      "coref: 86\n",
      "file num: 274\n",
      "coref: 87\n",
      "file num: 275\n",
      "coref: 88\n",
      "file num: 276\n",
      "file num: 277\n",
      "file num: 278\n",
      "file num: 279\n",
      "file num: 280\n",
      "file num: 281\n",
      "file num: 282\n",
      "file num: 283\n",
      "file num: 284\n",
      "file num: 285\n",
      "file num: 286\n",
      "file num: 287\n",
      "file num: 288\n",
      "file num: 289\n",
      "file num: 290\n",
      "file num: 291\n",
      "file num: 292\n",
      "file num: 293\n",
      "file num: 294\n",
      "file num: 295\n",
      "file num: 296\n",
      "file num: 297\n",
      "file num: 298\n",
      "file num: 299\n",
      "file num: 300\n",
      "file num: 301\n",
      "file num: 302\n",
      "file num: 303\n",
      "file num: 304\n",
      "file num: 305\n",
      "file num: 306\n",
      "file num: 307\n",
      "file num: 308\n",
      "file num: 309\n",
      "file num: 310\n",
      "file num: 311\n",
      "file num: 312\n",
      "file num: 313\n",
      "file num: 314\n",
      "file num: 315\n",
      "file num: 316\n",
      "file num: 317\n",
      "file num: 318\n",
      "file num: 319\n",
      "file num: 320\n",
      "file num: 321\n",
      "file num: 322\n",
      "file num: 323\n",
      "file num: 324\n",
      "file num: 325\n",
      "file num: 326\n",
      "file num: 327\n",
      "file num: 328\n",
      "file num: 329\n",
      "file num: 330\n",
      "file num: 331\n",
      "file num: 332\n",
      "file num: 333\n",
      "file num: 334\n",
      "file num: 335\n",
      "file num: 336\n",
      "file num: 337\n",
      "file num: 338\n",
      "file num: 339\n",
      "file num: 340\n",
      "file num: 341\n",
      "file num: 342\n",
      "file num: 343\n",
      "file num: 344\n",
      "file num: 345\n",
      "file num: 346\n",
      "file num: 347\n",
      "file num: 348\n",
      "file num: 349\n",
      "file num: 350\n",
      "file num: 351\n",
      "file num: 352\n",
      "file num: 353\n",
      "file num: 354\n",
      "file num: 355\n",
      "file num: 356\n",
      "file num: 357\n",
      "file num: 358\n",
      "file num: 359\n",
      "file num: 360\n",
      "file num: 361\n",
      "file num: 362\n",
      "file num: 363\n",
      "file num: 364\n",
      "file num: 365\n",
      "file num: 366\n",
      "file num: 367\n",
      "file num: 368\n",
      "file num: 369\n",
      "file num: 370\n",
      "file num: 371\n",
      "file num: 372\n",
      "file num: 373\n",
      "file num: 374\n",
      "file num: 375\n",
      "file num: 376\n",
      "file num: 377\n",
      "file num: 378\n",
      "file num: 379\n",
      "file num: 380\n",
      "file num: 381\n",
      "file num: 382\n",
      "file num: 383\n",
      "file num: 384\n",
      "file num: 385\n",
      "file num: 386\n",
      "file num: 387\n",
      "file num: 388\n",
      "file num: 389\n",
      "file num: 390\n",
      "file num: 391\n",
      "file num: 392\n",
      "file num: 393\n",
      "file num: 394\n",
      "file num: 395\n",
      "file num: 396\n",
      "file num: 397\n",
      "file num: 398\n",
      "file num: 399\n",
      "file num: 400\n",
      "file num: 401\n",
      "file num: 402\n",
      "file num: 403\n",
      "file num: 404\n",
      "file num: 405\n",
      "file num: 406\n",
      "file num: 407\n",
      "file num: 408\n",
      "file num: 409\n",
      "file num: 410\n",
      "file num: 411\n",
      "file num: 412\n",
      "file num: 413\n",
      "file num: 414\n",
      "file num: 415\n",
      "file num: 416\n",
      "file num: 417\n",
      "file num: 418\n",
      "file num: 419\n",
      "file num: 420\n",
      "file num: 421\n",
      "file num: 422\n",
      "file num: 423\n",
      "file num: 424\n",
      "file num: 425\n",
      "file num: 426\n",
      "file num: 427\n",
      "file num: 428\n",
      "file num: 429\n",
      "file num: 430\n",
      "file num: 431\n",
      "file num: 432\n",
      "file num: 433\n",
      "file num: 434\n",
      "file num: 435\n",
      "file num: 436\n",
      "file num: 437\n",
      "file num: 438\n",
      "file num: 439\n",
      "file num: 440\n",
      "file num: 441\n",
      "file num: 442\n",
      "file num: 443\n",
      "file num: 444\n",
      "file num: 445\n",
      "file num: 446\n",
      "file num: 447\n",
      "file num: 448\n",
      "file num: 449\n",
      "file num: 450\n",
      "file num: 451\n",
      "file num: 452\n",
      "file num: 453\n",
      "file num: 454\n",
      "file num: 455\n",
      "file num: 456\n",
      "file num: 457\n",
      "file num: 458\n",
      "file num: 459\n",
      "file num: 460\n",
      "file num: 461\n",
      "file num: 462\n",
      "file num: 463\n",
      "file num: 464\n",
      "file num: 465\n",
      "file num: 466\n",
      "file num: 467\n",
      "file num: 468\n",
      "file num: 469\n",
      "file num: 470\n",
      "file num: 471\n",
      "file num: 472\n",
      "file num: 473\n",
      "file num: 474\n",
      "file num: 475\n",
      "file num: 476\n",
      "file num: 477\n",
      "file num: 478\n",
      "file num: 479\n",
      "file num: 480\n",
      "file num: 481\n",
      "file num: 482\n",
      "file num: 483\n",
      "file num: 484\n",
      "file num: 485\n",
      "file num: 486\n",
      "file num: 487\n",
      "file num: 488\n",
      "file num: 489\n",
      "file num: 490\n",
      "file num: 491\n",
      "file num: 492\n",
      "file num: 493\n",
      "file num: 494\n",
      "file num: 495\n",
      "file num: 496\n",
      "file num: 497\n",
      "file num: 498\n",
      "file num: 499\n",
      "file num: 500\n",
      "file num: 501\n",
      "file num: 502\n",
      "file num: 503\n",
      "file num: 504\n",
      "file num: 505\n",
      "file num: 506\n",
      "file num: 507\n",
      "file num: 508\n",
      "file num: 509\n",
      "file num: 510\n",
      "file num: 511\n",
      "file num: 512\n",
      "file num: 513\n",
      "file num: 514\n",
      "file num: 515\n",
      "file num: 516\n",
      "file num: 517\n",
      "file num: 518\n",
      "file num: 519\n",
      "file num: 520\n",
      "file num: 521\n",
      "file num: 522\n",
      "file num: 523\n",
      "file num: 524\n",
      "file num: 525\n",
      "file num: 526\n",
      "file num: 527\n",
      "file num: 528\n",
      "file num: 529\n",
      "file num: 530\n",
      "file num: 531\n",
      "file num: 532\n",
      "file num: 533\n",
      "file num: 534\n",
      "file num: 535\n",
      "file num: 536\n",
      "file num: 537\n",
      "file num: 538\n",
      "file num: 539\n",
      "file num: 540\n",
      "file num: 541\n",
      "file num: 542\n",
      "file num: 543\n",
      "file num: 544\n",
      "file num: 545\n",
      "file num: 546\n",
      "file num: 547\n",
      "file num: 548\n",
      "file num: 549\n",
      "file num: 550\n",
      "file num: 551\n",
      "file num: 552\n",
      "file num: 553\n",
      "file num: 554\n",
      "file num: 555\n",
      "file num: 556\n",
      "file num: 557\n",
      "file num: 558\n",
      "file num: 559\n",
      "file num: 560\n",
      "file num: 561\n",
      "file num: 562\n",
      "file num: 563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file num: 564\n",
      "file num: 565\n",
      "file num: 566\n",
      "file num: 567\n",
      "file num: 568\n",
      "file num: 569\n",
      "file num: 570\n",
      "file num: 571\n",
      "file num: 572\n",
      "file num: 573\n",
      "file num: 574\n",
      "file num: 575\n",
      "file num: 576\n",
      "file num: 577\n",
      "file num: 578\n",
      "file num: 579\n",
      "file num: 580\n",
      "file num: 581\n",
      "file num: 582\n",
      "file num: 583\n",
      "file num: 584\n",
      "file num: 585\n",
      "file num: 586\n",
      "file num: 587\n",
      "file num: 588\n",
      "file num: 589\n",
      "file num: 590\n",
      "file num: 591\n",
      "file num: 592\n",
      "file num: 593\n",
      "file num: 594\n",
      "file num: 595\n",
      "file num: 596\n",
      "file num: 597\n",
      "file num: 598\n",
      "file num: 599\n",
      "file num: 600\n",
      "file num: 601\n",
      "file num: 602\n",
      "file num: 603\n",
      "file num: 604\n",
      "file num: 605\n",
      "file num: 606\n",
      "file num: 607\n",
      "file num: 608\n",
      "file num: 609\n",
      "file num: 610\n",
      "file num: 611\n",
      "file num: 612\n",
      "file num: 613\n",
      "file num: 614\n",
      "file num: 615\n",
      "file num: 616\n",
      "file num: 617\n",
      "file num: 618\n",
      "file num: 619\n",
      "file num: 620\n",
      "file num: 621\n",
      "file num: 622\n",
      "file num: 623\n",
      "file num: 624\n",
      "file num: 625\n",
      "file num: 626\n",
      "file num: 627\n",
      "file num: 628\n",
      "file num: 629\n",
      "file num: 630\n",
      "file num: 631\n",
      "file num: 632\n",
      "file num: 633\n",
      "file num: 634\n",
      "file num: 635\n",
      "file num: 636\n",
      "file num: 637\n",
      "file num: 638\n",
      "file num: 639\n",
      "file num: 640\n",
      "file num: 641\n",
      "file num: 642\n",
      "file num: 643\n",
      "file num: 644\n",
      "file num: 645\n",
      "file num: 646\n",
      "file num: 647\n",
      "file num: 648\n",
      "file num: 649\n",
      "file num: 650\n",
      "file num: 651\n",
      "file num: 652\n",
      "file num: 653\n",
      "file num: 654\n",
      "file num: 655\n",
      "file num: 656\n",
      "file num: 657\n",
      "file num: 658\n",
      "file num: 659\n",
      "file num: 660\n",
      "file num: 661\n",
      "file num: 662\n",
      "file num: 663\n",
      "file num: 664\n",
      "file num: 665\n",
      "file num: 666\n",
      "file num: 667\n",
      "file num: 668\n",
      "file num: 669\n",
      "file num: 670\n",
      "file num: 671\n",
      "file num: 672\n",
      "file num: 673\n",
      "file num: 674\n",
      "file num: 675\n",
      "file num: 676\n",
      "file num: 677\n",
      "file num: 678\n",
      "file num: 679\n",
      "file num: 680\n",
      "file num: 681\n",
      "file num: 682\n",
      "file num: 683\n",
      "file num: 684\n",
      "file num: 685\n",
      "file num: 686\n",
      "file num: 687\n",
      "file num: 688\n",
      "file num: 689\n",
      "file num: 690\n",
      "file num: 691\n",
      "file num: 692\n",
      "file num: 693\n",
      "file num: 694\n",
      "file num: 695\n",
      "file num: 696\n",
      "file num: 697\n",
      "file num: 698\n",
      "file num: 699\n",
      "file num: 700\n",
      "file num: 701\n",
      "file num: 702\n",
      "file num: 703\n",
      "file num: 704\n",
      "file num: 705\n",
      "file num: 706\n",
      "file num: 707\n",
      "file num: 708\n",
      "file num: 709\n",
      "file num: 710\n",
      "file num: 711\n",
      "file num: 712\n",
      "file num: 713\n",
      "file num: 714\n",
      "file num: 715\n",
      "file num: 716\n",
      "file num: 717\n",
      "file num: 718\n",
      "file num: 719\n",
      "file num: 720\n",
      "file num: 721\n",
      "file num: 722\n",
      "file num: 723\n",
      "file num: 724\n",
      "file num: 725\n",
      "file num: 726\n",
      "file num: 727\n",
      "file num: 728\n",
      "file num: 729\n",
      "file num: 730\n",
      "file num: 731\n",
      "file num: 732\n",
      "file num: 733\n",
      "file num: 734\n",
      "file num: 735\n",
      "file num: 736\n",
      "file num: 737\n",
      "file num: 738\n",
      "file num: 739\n",
      "file num: 740\n",
      "file num: 741\n",
      "file num: 742\n",
      "file num: 743\n",
      "file num: 744\n",
      "file num: 745\n",
      "file num: 746\n",
      "file num: 747\n",
      "file num: 748\n",
      "file num: 749\n",
      "file num: 750\n",
      "file num: 751\n",
      "file num: 752\n",
      "file num: 753\n",
      "file num: 754\n",
      "file num: 755\n",
      "file num: 756\n",
      "file num: 757\n",
      "file num: 758\n",
      "file num: 759\n",
      "file num: 760\n",
      "file num: 761\n",
      "file num: 762\n",
      "file num: 763\n",
      "file num: 764\n",
      "file num: 765\n",
      "file num: 766\n",
      "file num: 767\n",
      "file num: 768\n",
      "file num: 769\n",
      "file num: 770\n",
      "file num: 771\n",
      "file num: 772\n",
      "file num: 773\n",
      "file num: 774\n",
      "file num: 775\n",
      "file num: 776\n",
      "file num: 777\n",
      "file num: 778\n",
      "file num: 779\n",
      "file num: 780\n",
      "file num: 781\n",
      "file num: 782\n",
      "file num: 783\n",
      "file num: 784\n",
      "file num: 785\n",
      "file num: 786\n",
      "file num: 787\n",
      "file num: 788\n",
      "file num: 789\n",
      "file num: 790\n",
      "file num: 791\n",
      "file num: 792\n",
      "file num: 793\n",
      "file num: 794\n",
      "file num: 795\n",
      "file num: 796\n",
      "file num: 797\n",
      "file num: 798\n",
      "file num: 799\n",
      "file num: 800\n",
      "file num: 801\n",
      "file num: 802\n",
      "file num: 803\n",
      "file num: 804\n",
      "file num: 805\n",
      "file num: 806\n",
      "file num: 807\n",
      "file num: 808\n",
      "file num: 809\n",
      "file num: 810\n",
      "file num: 811\n",
      "file num: 812\n",
      "file num: 813\n",
      "file num: 814\n",
      "file num: 815\n",
      "file num: 816\n",
      "file num: 817\n",
      "file num: 818\n",
      "file num: 819\n",
      "file num: 820\n",
      "file num: 821\n",
      "file num: 822\n",
      "file num: 823\n",
      "file num: 824\n",
      "file num: 825\n",
      "file num: 826\n",
      "file num: 827\n",
      "file num: 828\n",
      "file num: 829\n",
      "file num: 830\n",
      "file num: 831\n",
      "file num: 832\n",
      "file num: 833\n",
      "file num: 834\n",
      "file num: 835\n",
      "file num: 836\n",
      "file num: 837\n",
      "file num: 838\n",
      "file num: 839\n",
      "file num: 840\n",
      "file num: 841\n",
      "file num: 842\n",
      "file num: 843\n",
      "file num: 844\n",
      "file num: 845\n",
      "file num: 846\n",
      "file num: 847\n",
      "file num: 848\n",
      "file num: 849\n",
      "file num: 850\n",
      "file num: 851\n",
      "file num: 852\n",
      "file num: 853\n",
      "file num: 854\n",
      "file num: 855\n",
      "file num: 856\n",
      "file num: 857\n",
      "file num: 858\n",
      "file num: 859\n",
      "file num: 860\n",
      "file num: 861\n",
      "file num: 862\n",
      "file num: 863\n",
      "file num: 864\n",
      "file num: 865\n",
      "file num: 866\n",
      "file num: 867\n",
      "file num: 868\n",
      "file num: 869\n",
      "file num: 870\n",
      "file num: 871\n",
      "file num: 872\n",
      "file num: 873\n",
      "file num: 874\n",
      "file num: 875\n",
      "file num: 876\n",
      "file num: 877\n",
      "file num: 878\n",
      "file num: 879\n",
      "file num: 880\n",
      "file num: 881\n",
      "file num: 882\n",
      "file num: 883\n",
      "file num: 884\n",
      "file num: 885\n",
      "file num: 886\n",
      "file num: 887\n",
      "file num: 888\n",
      "file num: 889\n",
      "file num: 890\n",
      "file num: 891\n",
      "file num: 892\n",
      "file num: 893\n",
      "file num: 894\n",
      "file num: 895\n",
      "file num: 896\n",
      "file num: 897\n",
      "file num: 898\n",
      "file num: 899\n",
      "file num: 900\n",
      "file num: 901\n",
      "file num: 902\n",
      "file num: 903\n",
      "file num: 904\n",
      "file num: 905\n",
      "file num: 906\n",
      "file num: 907\n",
      "file num: 908\n",
      "file num: 909\n",
      "file num: 910\n",
      "file num: 911\n",
      "file num: 912\n",
      "file num: 913\n",
      "file num: 914\n",
      "file num: 915\n",
      "file num: 916\n",
      "file num: 917\n",
      "file num: 918\n",
      "file num: 919\n",
      "file num: 920\n",
      "file num: 921\n",
      "file num: 922\n",
      "file num: 923\n",
      "file num: 924\n",
      "file num: 925\n",
      "file num: 926\n",
      "file num: 927\n",
      "file num: 928\n",
      "file num: 929\n",
      "file num: 930\n",
      "file num: 931\n",
      "file num: 932\n",
      "file num: 933\n",
      "file num: 934\n",
      "file num: 935\n",
      "file num: 936\n",
      "file num: 937\n",
      "file num: 938\n",
      "file num: 939\n",
      "file num: 940\n",
      "file num: 941\n",
      "file num: 942\n",
      "file num: 943\n",
      "file num: 944\n",
      "file num: 945\n",
      "file num: 946\n",
      "file num: 947\n",
      "file num: 948\n",
      "file num: 949\n",
      "file num: 950\n",
      "file num: 951\n",
      "file num: 952\n",
      "file num: 953\n",
      "file num: 954\n",
      "file num: 955\n",
      "file num: 956\n",
      "file num: 957\n",
      "file num: 958\n",
      "file num: 959\n",
      "file num: 960\n",
      "file num: 961\n",
      "file num: 962\n",
      "file num: 963\n",
      "file num: 964\n",
      "file num: 965\n",
      "file num: 966\n",
      "file num: 967\n",
      "file num: 968\n",
      "file num: 969\n",
      "file num: 970\n",
      "file num: 971\n",
      "file num: 972\n",
      "file num: 973\n",
      "file num: 974\n",
      "file num: 975\n",
      "file num: 976\n",
      "file num: 977\n",
      "file num: 978\n",
      "file num: 979\n",
      "file num: 980\n",
      "file num: 981\n",
      "file num: 982\n",
      "file num: 983\n",
      "file num: 984\n",
      "file num: 985\n",
      "file num: 986\n",
      "file num: 987\n",
      "file num: 988\n",
      "file num: 989\n",
      "file num: 990\n",
      "file num: 991\n",
      "file num: 992\n",
      "file num: 993\n",
      "file num: 994\n",
      "file num: 995\n",
      "file num: 996\n",
      "file num: 997\n",
      "file num: 998\n",
      "file num: 999\n",
      "file num: 1000\n",
      "file num: 1001\n",
      "file num: 1002\n",
      "file num: 1003\n",
      "file num: 1004\n",
      "file num: 1005\n",
      "file num: 1006\n",
      "file num: 1007\n",
      "file num: 1008\n",
      "file num: 1009\n",
      "file num: 1010\n",
      "file num: 1011\n",
      "file num: 1012\n",
      "file num: 1013\n",
      "file num: 1014\n",
      "file num: 1015\n",
      "file num: 1016\n",
      "file num: 1017\n",
      "file num: 1018\n",
      "file num: 1019\n",
      "file num: 1020\n",
      "file num: 1021\n",
      "file num: 1022\n",
      "file num: 1023\n",
      "file num: 1024\n",
      "file num: 1025\n",
      "file num: 1026\n",
      "file num: 1027\n",
      "file num: 1028\n",
      "file num: 1029\n",
      "file num: 1030\n",
      "file num: 1031\n",
      "file num: 1032\n",
      "file num: 1033\n",
      "file num: 1034\n",
      "file num: 1035\n",
      "file num: 1036\n",
      "file num: 1037\n",
      "file num: 1038\n",
      "file num: 1039\n",
      "file num: 1040\n",
      "file num: 1041\n",
      "file num: 1042\n",
      "file num: 1043\n",
      "file num: 1044\n",
      "file num: 1045\n",
      "file num: 1046\n",
      "file num: 1047\n",
      "file num: 1048\n",
      "file num: 1049\n",
      "file num: 1050\n",
      "file num: 1051\n",
      "file num: 1052\n",
      "file num: 1053\n",
      "file num: 1054\n",
      "file num: 1055\n",
      "file num: 1056\n",
      "file num: 1057\n",
      "file num: 1058\n",
      "file num: 1059\n",
      "file num: 1060\n",
      "file num: 1061\n",
      "file num: 1062\n",
      "file num: 1063\n",
      "file num: 1064\n",
      "file num: 1065\n",
      "file num: 1066\n",
      "file num: 1067\n",
      "file num: 1068\n",
      "file num: 1069\n",
      "file num: 1070\n",
      "file num: 1071\n",
      "file num: 1072\n",
      "file num: 1073\n",
      "file num: 1074\n",
      "file num: 1075\n",
      "file num: 1076\n",
      "file num: 1077\n",
      "file num: 1078\n",
      "file num: 1079\n",
      "file num: 1080\n",
      "file num: 1081\n",
      "file num: 1082\n",
      "file num: 1083\n",
      "file num: 1084\n",
      "file num: 1085\n",
      "file num: 1086\n",
      "file num: 1087\n",
      "file num: 1088\n",
      "file num: 1089\n",
      "file num: 1090\n",
      "file num: 1091\n",
      "file num: 1092\n",
      "file num: 1093\n",
      "file num: 1094\n",
      "file num: 1095\n",
      "file num: 1096\n",
      "file num: 1097\n",
      "file num: 1098\n",
      "file num: 1099\n",
      "file num: 1100\n",
      "file num: 1101\n",
      "file num: 1102\n",
      "file num: 1103\n",
      "file num: 1104\n",
      "file num: 1105\n",
      "file num: 1106\n",
      "file num: 1107\n",
      "file num: 1108\n",
      "file num: 1109\n",
      "file num: 1110\n",
      "file num: 1111\n",
      "file num: 1112\n",
      "file num: 1113\n",
      "file num: 1114\n",
      "file num: 1115\n",
      "file num: 1116\n",
      "file num: 1117\n",
      "file num: 1118\n",
      "file num: 1119\n",
      "file num: 1120\n",
      "file num: 1121\n",
      "file num: 1122\n",
      "file num: 1123\n",
      "file num: 1124\n",
      "file num: 1125\n",
      "file num: 1126\n",
      "file num: 1127\n",
      "file num: 1128\n",
      "file num: 1129\n",
      "file num: 1130\n",
      "file num: 1131\n",
      "file num: 1132\n",
      "file num: 1133\n",
      "file num: 1134\n",
      "file num: 1135\n",
      "file num: 1136\n",
      "file num: 1137\n",
      "file num: 1138\n",
      "file num: 1139\n",
      "file num: 1140\n",
      "file num: 1141\n",
      "file num: 1142\n",
      "file num: 1143\n",
      "file num: 1144\n",
      "file num: 1145\n",
      "file num: 1146\n",
      "file num: 1147\n",
      "file num: 1148\n",
      "file num: 1149\n",
      "file num: 1150\n",
      "file num: 1151\n",
      "file num: 1152\n",
      "file num: 1153\n",
      "file num: 1154\n",
      "file num: 1155\n",
      "file num: 1156\n",
      "file num: 1157\n",
      "file num: 1158\n",
      "file num: 1159\n",
      "file num: 1160\n",
      "file num: 1161\n",
      "file num: 1162\n",
      "file num: 1163\n",
      "file num: 1164\n",
      "file num: 1165\n",
      "file num: 1166\n",
      "file num: 1167\n",
      "file num: 1168\n",
      "file num: 1169\n",
      "file num: 1170\n",
      "file num: 1171\n",
      "file num: 1172\n",
      "file num: 1173\n",
      "file num: 1174\n",
      "file num: 1175\n",
      "file num: 1176\n",
      "file num: 1177\n",
      "file num: 1178\n",
      "file num: 1179\n",
      "file num: 1180\n",
      "file num: 1181\n",
      "file num: 1182\n",
      "file num: 1183\n",
      "file num: 1184\n",
      "file num: 1185\n",
      "file num: 1186\n",
      "file num: 1187\n",
      "file num: 1188\n",
      "file num: 1189\n",
      "file num: 1190\n",
      "file num: 1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file num: 1192\n",
      "file num: 1193\n",
      "file num: 1194\n",
      "file num: 1195\n",
      "file num: 1196\n",
      "file num: 1197\n",
      "file num: 1198\n",
      "file num: 1199\n",
      "file num: 1200\n",
      "file num: 1201\n",
      "file num: 1202\n",
      "coref: 89\n",
      "file num: 1203\n",
      "coref: 90\n",
      "file num: 1204\n",
      "coref: 91\n",
      "file num: 1205\n",
      "coref: 92\n",
      "file num: 1206\n",
      "coref: 93\n",
      "file num: 1207\n",
      "coref: 94\n",
      "file num: 1208\n",
      "coref: 95\n",
      "file num: 1209\n",
      "file num: 1210\n",
      "coref: 96\n",
      "file num: 1211\n",
      "coref: 97\n",
      "file num: 1212\n",
      "coref: 98\n",
      "file num: 1213\n",
      "coref: 99\n",
      "file num: 1214\n",
      "coref: 100\n",
      "file num: 1215\n",
      "file num: 1216\n",
      "file num: 1217\n",
      "file num: 1218\n",
      "file num: 1219\n",
      "file num: 1220\n",
      "coref: 101\n",
      "file num: 1221\n",
      "coref: 102\n",
      "file num: 1222\n",
      "coref: 103\n",
      "file num: 1223\n",
      "coref: 104\n",
      "file num: 1224\n",
      "coref: 105\n",
      "file num: 1225\n",
      "coref: 106\n",
      "file num: 1226\n",
      "coref: 107\n",
      "file num: 1227\n",
      "file num: 1228\n",
      "file num: 1229\n",
      "file num: 1230\n",
      "file num: 1231\n",
      "file num: 1232\n",
      "file num: 1233\n",
      "coref: 108\n",
      "file num: 1234\n",
      "coref: 109\n",
      "file num: 1235\n",
      "coref: 110\n",
      "file num: 1236\n",
      "file num: 1237\n",
      "file num: 1238\n",
      "file num: 1239\n",
      "file num: 1240\n",
      "coref: 111\n",
      "file num: 1241\n",
      "coref: 112\n",
      "file num: 1242\n",
      "coref: 113\n",
      "file num: 1243\n",
      "coref: 114\n",
      "file num: 1244\n",
      "coref: 115\n",
      "file num: 1245\n",
      "coref: 116\n",
      "file num: 1246\n",
      "coref: 117\n",
      "file num: 1247\n",
      "coref: 118\n",
      "file num: 1248\n",
      "coref: 119\n",
      "file num: 1249\n",
      "coref: 120\n",
      "file num: 1250\n",
      "file num: 1251\n",
      "file num: 1252\n",
      "file num: 1253\n",
      "file num: 1254\n",
      "file num: 1255\n",
      "file num: 1256\n",
      "coref: 121\n",
      "file num: 1257\n",
      "coref: 122\n",
      "file num: 1258\n",
      "coref: 123\n",
      "file num: 1259\n",
      "coref: 124\n",
      "file num: 1260\n",
      "coref: 125\n",
      "file num: 1261\n",
      "coref: 126\n",
      "file num: 1262\n",
      "coref: 127\n",
      "file num: 1263\n",
      "coref: 128\n",
      "file num: 1264\n",
      "coref: 129\n",
      "file num: 1265\n",
      "coref: 130\n",
      "file num: 1266\n",
      "coref: 131\n",
      "file num: 1267\n",
      "coref: 132\n",
      "file num: 1268\n",
      "coref: 133\n",
      "file num: 1269\n",
      "coref: 134\n",
      "file num: 1270\n",
      "coref: 135\n",
      "file num: 1271\n",
      "coref: 136\n",
      "file num: 1272\n",
      "coref: 137\n",
      "file num: 1273\n",
      "coref: 138\n",
      "file num: 1274\n",
      "coref: 139\n",
      "file num: 1275\n",
      "coref: 140\n",
      "file num: 1276\n",
      "coref: 141\n",
      "file num: 1277\n",
      "coref: 142\n",
      "file num: 1278\n",
      "coref: 143\n",
      "file num: 1279\n",
      "coref: 144\n",
      "file num: 1280\n",
      "coref: 145\n",
      "file num: 1281\n",
      "coref: 146\n",
      "file num: 1282\n",
      "coref: 147\n",
      "file num: 1283\n",
      "coref: 148\n",
      "file num: 1284\n",
      "coref: 149\n",
      "file num: 1285\n",
      "coref: 150\n",
      "file num: 1286\n",
      "coref: 151\n",
      "file num: 1287\n",
      "coref: 152\n",
      "file num: 1288\n",
      "coref: 153\n",
      "file num: 1289\n",
      "coref: 154\n",
      "file num: 1290\n",
      "coref: 155\n",
      "file num: 1291\n",
      "coref: 156\n",
      "file num: 1292\n",
      "coref: 157\n",
      "file num: 1293\n",
      "coref: 158\n",
      "file num: 1294\n",
      "coref: 159\n",
      "file num: 1295\n",
      "file num: 1296\n",
      "file num: 1297\n",
      "file num: 1298\n",
      "file num: 1299\n",
      "coref: 160\n",
      "file num: 1300\n",
      "coref: 161\n",
      "file num: 1301\n",
      "coref: 162\n",
      "file num: 1302\n",
      "coref: 163\n",
      "file num: 1303\n",
      "coref: 164\n",
      "file num: 1304\n",
      "coref: 165\n",
      "file num: 1305\n",
      "coref: 166\n",
      "file num: 1306\n",
      "coref: 167\n",
      "file num: 1307\n",
      "coref: 168\n",
      "file num: 1308\n",
      "coref: 169\n",
      "file num: 1309\n",
      "coref: 170\n",
      "file num: 1310\n",
      "coref: 171\n",
      "file num: 1311\n",
      "coref: 172\n",
      "file num: 1312\n",
      "coref: 173\n",
      "file num: 1313\n",
      "coref: 174\n",
      "file num: 1314\n",
      "coref: 175\n",
      "file num: 1315\n",
      "coref: 176\n",
      "file num: 1316\n",
      "coref: 177\n",
      "file num: 1317\n",
      "coref: 178\n",
      "file num: 1318\n",
      "coref: 179\n",
      "file num: 1319\n",
      "coref: 180\n",
      "file num: 1320\n",
      "coref: 181\n",
      "file num: 1321\n",
      "coref: 182\n",
      "file num: 1322\n",
      "coref: 183\n",
      "file num: 1323\n",
      "coref: 184\n",
      "file num: 1324\n",
      "coref: 185\n",
      "file num: 1325\n",
      "coref: 186\n",
      "file num: 1326\n",
      "coref: 187\n",
      "file num: 1327\n",
      "coref: 188\n",
      "file num: 1328\n",
      "file num: 1329\n",
      "coref: 189\n",
      "file num: 1330\n",
      "coref: 190\n",
      "file num: 1331\n",
      "coref: 191\n",
      "file num: 1332\n",
      "coref: 192\n",
      "file num: 1333\n",
      "coref: 193\n",
      "file num: 1334\n",
      "coref: 194\n",
      "file num: 1335\n",
      "coref: 195\n",
      "file num: 1336\n",
      "coref: 196\n",
      "file num: 1337\n",
      "coref: 197\n",
      "file num: 1338\n",
      "coref: 198\n",
      "file num: 1339\n",
      "coref: 199\n",
      "file num: 1340\n",
      "coref: 200\n",
      "file num: 1341\n",
      "coref: 201\n",
      "file num: 1342\n",
      "coref: 202\n",
      "file num: 1343\n",
      "coref: 203\n",
      "file num: 1344\n",
      "coref: 204\n",
      "file num: 1345\n",
      "coref: 205\n",
      "file num: 1346\n",
      "coref: 206\n",
      "file num: 1347\n",
      "file num: 1348\n",
      "file num: 1349\n",
      "file num: 1350\n",
      "file num: 1351\n",
      "file num: 1352\n",
      "file num: 1353\n",
      "file num: 1354\n",
      "file num: 1355\n",
      "file num: 1356\n",
      "coref: 207\n",
      "file num: 1357\n",
      "coref: 208\n",
      "file num: 1358\n",
      "coref: 209\n",
      "file num: 1359\n",
      "coref: 210\n",
      "file num: 1360\n",
      "coref: 211\n",
      "file num: 1361\n",
      "coref: 212\n",
      "file num: 1362\n",
      "coref: 213\n",
      "file num: 1363\n",
      "coref: 214\n",
      "file num: 1364\n",
      "coref: 215\n",
      "file num: 1365\n",
      "coref: 216\n",
      "file num: 1366\n",
      "coref: 217\n",
      "file num: 1367\n",
      "coref: 218\n",
      "file num: 1368\n",
      "coref: 219\n",
      "file num: 1369\n",
      "coref: 220\n",
      "file num: 1370\n",
      "coref: 221\n"
     ]
    }
   ],
   "source": [
    "input_files_vector = []\n",
    "output_files_vector = []\n",
    "num = 0\n",
    "count = 0\n",
    "for j in range(0, len(list_of_conll_files)):\n",
    "    num += 1\n",
    "    print ('file num: ' + str(num))\n",
    "    i_vector, o_vector = train_network_data(list_of_conll_files[j])\n",
    "    if len(i_vector) > 0:\n",
    "        input_files_vector.append(i_vector)\n",
    "        output_files_vector.append(o_vector)\n",
    "        count += 1\n",
    "        print ('coref: ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ffnn_input = []\n",
    "ffnn_output = []\n",
    "for inp_vector, out_vector in zip(input_files_vector, output_files_vector):\n",
    "    for inp, out in zip(inp_vector, out_vector):\n",
    "        ffnn_input.append(inp)\n",
    "        ffnn_output.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268952"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ffnn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/ffnn_input_dev', ffnn_input, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/home/vishesh/TUM/Thesis/Coreference-Resolution/data/processed/ffnn_output_dev', ffnn_output, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
